{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 파일에서 PromptTemplate 읽어오기\n",
        "- 외부 파일에서 프롬프트 템플릿을 읽어와 사용하는 방법입니다\n",
        "- 프롬프트를 코드와 분리하여 관리할 수 있어 유지보수가 용이합니다\n",
        "- 다양한 파일 형식(텍스트, JSON, YAML)에서 프롬프트를 불러올 수 있습니다\n",
        "    - `텍스트 파일`: 간단한 프롬프트 템플릿 저장\n",
        "    - `JSON 파일`: 구조화된 프롬프트와 메타데이터 관리\n",
        "    - `YAML 파일`: 사람이 읽기 쉬운 형태로 프롬프트 관리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# LLM 객체 생성\n",
        "llm = ChatOllama(model=\"midm-2.0-base-instruct-q5_k_m\", temperature=0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. 텍스트 파일에서 프롬프트 가져오기\n",
        "- 가장 간단한 방법으로 `.txt` 파일에 프롬프트 템플릿을 저장합니다\n",
        "- 변수는 `{변수명}` 형태로 표현합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = \"./prompts/military_word.txt\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        template_content = f.read()\n",
        "\n",
        "print(template_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# PromptTemplate 객체 생성\n",
        "prompt_template = PromptTemplate(\n",
        "        input_variables=\"word\",\n",
        "        template=template_content\n",
        "    )\n",
        "\n",
        "print(prompt_template)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data = \"내무반\"\n",
        "\n",
        "formatted_prompt = prompt_template.format(word=test_data)\n",
        "response = llm.invoke(formatted_prompt)\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. YAML 파일에서 프롬프트 읽기\n",
        "- 사람이 읽기 쉬운 형태로 프롬프트 템플릿을 저장하는 방법\n",
        "- 주석 지원으로 프롬프트에 대한 설명과 문서화가 용이함\n",
        "- 복잡한 구조의 데이터도 직관적으로 표현 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7 (YAML 파일 읽기)\n",
        "import yaml\n",
        "\n",
        "file_path = \"./prompts/counselor_prompt.yaml\"\n",
        "\n",
        "# YAML 파일에서 데이터 읽기\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = yaml.safe_load(f)\n",
        "\n",
        "print(\"YAML 파일 내용:\")\n",
        "print(\"변수들:\", data[\"variables\"])\n",
        "print(\"템플릿:\")\n",
        "print(data[\"template\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# PromptTemplate 객체 생성\n",
        "counselor_prompt = PromptTemplate(\n",
        "    input_variables=data[\"variables\"],\n",
        "    template=data[\"template\"]\n",
        ")\n",
        "\n",
        "print(\"생성된 PromptTemplate:\")\n",
        "print(counselor_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YAML 파일 프롬프트 테스트\n",
        "test_data = {\n",
        "    \"topic\": \"동기들과의 관계\",\n",
        "    \"concern_type\": \"인간관계\",\n",
        "    \"service_period\": \"3개월차\",\n",
        "    \"concern_details\": \"동기들과 잘 어울리지 못하고, 항상 혼자 있게 됩니다.\"\n",
        "}\n",
        "\n",
        "formatted_prompt = counselor_prompt.format(**test_data)\n",
        "response = llm.invoke(formatted_prompt)\n",
        "\n",
        "print(\"입력:\", test_data)\n",
        "print(\"상담사의 조언:\")\n",
        "print(response.content)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
