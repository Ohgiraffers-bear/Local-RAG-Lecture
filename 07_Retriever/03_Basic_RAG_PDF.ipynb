{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7366a6d1",
   "metadata": {},
   "source": [
    "## RAG란?\n",
    "- 자연어 처리(NLP) 분야의 혁신적인 기술로, 기존 모델의 한계를 넘어서 정보 검색과 생성을 통합하는 방법론\n",
    "- 풍부한 정보를 담고 있는 대규모 문서 데이터베이스에서 관련정보를 검색하고, \n",
    "- 이를 통해 언어 모델이 더 정확하고 상세한 답변을 생성 할 수 있습니다.\n",
    "\n",
    "### 핵심 개념\n",
    "- **검색(Retrieval)**: 질문과 관련된 문서나 정보를 벡터 유사도 기반으로 찾기\n",
    "- **증강(Augmented)**: 찾은 정보를 언어 모델의 컨텍스트에 추가\n",
    "- **생성(Generation)**: 증강된 정보를 바탕으로 더 정확하고 신뢰할 수 있는 답변 생성\n",
    "\n",
    "\n",
    "### RAG의 장점\n",
    "1. 최신 정보 반영 가능 (지식 갱신이 간편)\n",
    "2. 출처 기반 응답 제공\n",
    "3. 도메인 특화 응답 가능\n",
    "\n",
    "### RAG의 기본구조\n",
    "\n",
    "![RAG.png](./images/RAG.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281ef186",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**RAG-FLOW**\n",
    "![RAG_Flow.png](./images/RAG_Flow.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c800d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## PDF를 문서로 사용해서 RAG 시스템 구축하기\n",
    "- 다음 실습 예시는 기본적인 RAG 구조를 구현합니다.\n",
    "- 추후, 개발을 진행할때는 각각의 구현 상황에 맞는 모듈로 바꾸는 것 만으로도 여러분들만의 RAG 시스템을 구축 할 수 있습니다.\n",
    "\n",
    "- 예시  \n",
    "지금 예시에서는 PDF를 읽어와 문서를 저장하고 있지만, 제공되는 문서가 Text일 경우 Docuemnt Loader 모듈을 바꾸어 사용할 수 있습니다.  \n",
    "또는, 현재는 LLM 모델을 로컬로 Ollama를 이용해 Mi:dm 모델을 사용하고 있지만, API 방식으로 바꾸어 구현 할 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60c58dd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**실습자료**\n",
    "- 제목 : 2025 병 복지 길라잡이  \n",
    "- 링크 : [국방부 홈페이지 자료위치 링크](https://www.mnd.go.kr/cop/pblictn/selectPublicationUser.do?siteId=mnd&componentId=14&categoryId=0&publicationSeq=1112&pageIndex=1&id=mnd_020704000000)  \n",
    "- 출처 : 국방부 복지정책과\n",
    "\n",
    "*링크에서 파일을 다운로드 받은후 data 폴더에 위치시켜주세요*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6cb4a6",
   "metadata": {},
   "source": [
    "### Step 1 : 문서 로드(Document Load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af979fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(\"data/Soldier-Benefits-Guide.pdf\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"10번째 문서 내용 : {docs[9].page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38daab9",
   "metadata": {},
   "source": [
    "메타데이터 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787e18b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[9].__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb2fcfb",
   "metadata": {},
   "source": [
    "### Step 2 : 문서 분할하기 (Text Splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab118584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# chunk size : 300자, overlap : 30자\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=30)\n",
    "\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"분할된 청크의수: {len(split_documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a70814",
   "metadata": {},
   "source": [
    "### Step 3 : 임베딩 준비하기 (Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f90d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# 1. HuggingFaceEmbeddings 모델 초기화\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"nlpai-lab/KURE-v1\",  # 모델 다운로드\n",
    "    model_kwargs={'device': 'cpu'},  # CPU 사용 (GPU가 있다면 'cuda'도 가능)\n",
    "    encode_kwargs={'normalize_embeddings': True}  # 벡터 정규화 활성화\n",
    ")\n",
    "\n",
    "print(f\"모델명: {embeddings.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6609e838",
   "metadata": {},
   "source": [
    "### Step 4 : Vector Store 생성 및 문서 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b035f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce0a26f",
   "metadata": {},
   "source": [
    "### Step 5 : Retriever 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1feaad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c61be1",
   "metadata": {},
   "source": [
    "### Step 6 : 프롬프트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e3e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"당신은 질문에 답변하는 작업을 수행하는 어시스턴트입니다.\n",
    "다음에 제공된 문맥 정보를 바탕으로 질문에 답하세요.\n",
    "정답을 모를 경우, 모른다고만 말하세요.\n",
    "답변은 반드시 한국어로 작성하세요.\n",
    "\n",
    "#문맥:\n",
    "{context}\n",
    "\n",
    "#질문:\n",
    "{question}\n",
    "\n",
    "#답변:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceb39b2",
   "metadata": {},
   "source": [
    "### Step 7 : LLM 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da8d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"midm-2.0-base-instruct-q5_k_m\",\n",
    "    temperature=0,  # 구조화된 출력을 위해 낮은 temperature 설정\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a14b6d",
   "metadata": {},
   "source": [
    "### Step 8 : 체인 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9556c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough(), # 다음 체인으로 값을 그대로 넘김\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f2e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"병사의 계급별 지급액이 어떻게 돼?\"\n",
    "response = chain.invoke(question)\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
