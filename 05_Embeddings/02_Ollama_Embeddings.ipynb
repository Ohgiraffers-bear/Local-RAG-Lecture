{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63164c99",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Ollama Embeddings\n",
    "\n",
    "`OllamaEmbeddings`는 LangChain에서 Ollama 플랫폼의 다양한 임베딩 모델을 활용할 수 있게 해주는 통합 인터페이스입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5e1b9d",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**특징**\n",
    "- 로컬 실행: Ollama 서버를 통해 로컬에서 실행됩니다\n",
    "- 빠른 속도: 로컬 서버를 통한 빠른 응답을 제공합니다\n",
    "- 무료 사용: API 비용이 없습니다\n",
    "- 개인정보 보호: 데이터가 외부로 전송되지 않습니다\n",
    "- 다양한 모델: 여러 임베딩 모델을 지원합니다\n",
    "\n",
    "**주요 매개변수**\n",
    "- `model`: 사용할 Ollama 임베딩 모델명 (예: \"nomic-embed-text\", \"snowflake-arctic-embed\")\n",
    "- `base_url`: Ollama 서버 URL (기본값: \"http://localhost:11434\") \n",
    "- `headers`: HTTP 헤더 설정 (선택사항)\n",
    "- `num_thread`: 스레드 수 설정 (선택사항)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c5d5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델 다운로드 (처음 실행 시 필요)\n",
    "# nomic-embed-text 모델은 다국어를 지원한다.\n",
    "!ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f68a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama 임베딩 모델 초기화\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# 임베딩 모델 설정\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",  # Ollama 임베딩 모델 지정\n",
    "    base_url=\"http://localhost:11434\",  # Ollama 서버 URL (기본값)\n",
    ")\n",
    "\n",
    "print(\"Ollama 임베딩 모델 로딩 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471b7379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 쿼리 임베딩 생성\n",
    "text = \"LangChain은 대화형 AI 애플리케이션 개발을 위한 프레임워크입니다.\"\n",
    "print(f\"원본 텍스트: {text}\")\n",
    "\n",
    "# 임베딩 생성\n",
    "query_embedding = embeddings.embed_query(text)\n",
    "\n",
    "print(f\"임베딩 차원: {len(query_embedding)}\")\n",
    "print(f\"임베딩 벡터 (처음 5개 값): {query_embedding[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc49f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 문서의 배치 임베딩 생성\n",
    "documents = [\n",
    "    \"LangChain은 대화형 AI 애플리케이션을 구축하기 위한 오픈소스 프레임워크입니다.\",\n",
    "    \"Ollama는 로컬에서 대화형 모델을 실행할 수 있는 플랫폼입니다.\",\n",
    "    \"임베딩은 텍스트를 고차원 벡터로 변환하는 기술입니다.\",\n",
    "    \"벡터 데이터베이스는 임베딩을 효율적으로 저장하고 검색할 수 있습니다.\",\n",
    "    \"RAG는 검색 증강 생성을 의미하며, 외부 지식을 활용하여 응답을 생성합니다.\"\n",
    "]\n",
    "\n",
    "print(\"문서 배치 임베딩 생성 중...\")\n",
    "doc_embeddings = embeddings.embed_documents(documents)\n",
    "\n",
    "print(f\"총 {len(doc_embeddings)}개 문서의 임베딩 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a706fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 유사도 계산\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"\\n=== 임베딩 유사도 계산 ===\")\n",
    "\n",
    "# 쿼리 임베딩 생성\n",
    "query_text = \"Ollama에 대해 알려주세요\"\n",
    "query_emb = embeddings.embed_query(query_text)\n",
    "\n",
    "# 유사도 계산을 위한 벡터 변환\n",
    "doc_matrix = np.array(doc_embeddings)\n",
    "query_vector = np.array(query_emb).reshape(1, -1)\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "similarities = cosine_similarity(query_vector, doc_matrix)[0]\n",
    "\n",
    "print(f\"쿼리: {query_text}\")\n",
    "print(\"\\n문서별 유사도:\")\n",
    "for i, (sim, doc) in enumerate(zip(similarities, documents)):\n",
    "    print(f\"문서 {i+1} (유사도: {sim:.4f}): {doc[:50]}...\")\n",
    "\n",
    "# 가장 유사한 문서 출력\n",
    "most_similar_idx = np.argmax(similarities)\n",
    "print(f\"\\n가장 유사한 문서: {documents[most_similar_idx]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
