{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "194e7018",
   "metadata": {},
   "source": [
    "# Embedding이란?\n",
    "**텍스트 → 수치 벡터(vector)** 로 변환하는 작업  \n",
    "즉, 사람의 언어를 컴퓨터가 이해할 수 있는 형식으로 바꾸는 것.\n",
    "\n",
    "=> `LangChain`에서 관련있는 문서를 검색 해 올 수 있어야 하기 때문에,   \n",
    "   문서를 수치 벡터화 시켜, 의미가 비슷한 문서를 찾을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77941443",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### HuggingFace Embeddings\n",
    "\n",
    "`HuggingFaceEmbeddings`는 LangChain에서 HuggingFaceHub의   \n",
    "다양한 임베딩 모델을 활용할 수 있게 해주는 통합 인터페이스입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b439a43",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**특징**\n",
    "- 로컬 실행: 인터넷 연결 없이도 사용 가능\n",
    "- 빠른 속도: 로컬에서 직접 실행되어 네트워크 지연 없음\n",
    "- 무료 사용: API 비용 없음\n",
    "- 개인정보 보호: 데이터가 외부로 전송되지 않음\n",
    "\n",
    "**주요 매개변수**\n",
    "- `model_name`: 사용할 HuggingFace 모델명\n",
    "- `model_kwargs`: 모델 초기화 시 전달할 파라미터\n",
    "- `encode_kwargs`: 인코딩 시 전달할 파라미터\n",
    "- `cache_folder`: 모델 캐시 저장 경로\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790a2262",
   "metadata": {},
   "source": [
    "nlpai-lab/KURE-v1은 sentence-transformers를 기반으로 동작하는 모델입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a89cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0befbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# 1. 임베딩 객체 생성\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"nlpai-lab/KURE-v1\",  # 모델 다운로드드\n",
    "    model_kwargs={'device': 'cpu'},  # CPU 사용 (GPU가 있다면 'cuda'도 가능)\n",
    "    encode_kwargs={'normalize_embeddings': True}  # 벡터 정규화 활성화\n",
    ")\n",
    "\n",
    "print(f\"모델명: {embeddings.model_name}\")\n",
    "print(\"모델 로딩 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb016b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 단일 쿼리 임베딩 생성\n",
    "text = \"LangChain은 대화형 AI 애플리케이션 개발을 위한 프레임워크입니다.\"\n",
    "print(f\"원본 텍스트: {text}\")\n",
    "\n",
    "# 임베딩 생성\n",
    "query_embedding = embeddings.embed_query(text)\n",
    "\n",
    "print(f\"임베딩 차원: {len(query_embedding)}\")\n",
    "print(f\"임베딩 벡터 (처음 5개 값): {query_embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1140e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 여러 문서의 임베딩 생성\n",
    "documents = [\n",
    "    \"LangChain은 대화형 AI 애플리케이션을 구축하기 위한 오픈소스 프레임워크입니다.\",\n",
    "    \"HuggingFace는 자연어 처리를 위한 최고의 플랫폼 중 하나입니다.\",\n",
    "    \"임베딩은 텍스트를 고차원 벡터로 변환하는 기술입니다.\",\n",
    "    \"벡터 데이터베이스는 임베딩을 효율적으로 저장하고 검색할 수 있습니다.\",\n",
    "    \"RAG는 검색 증강 생성을 의미하며, 외부 지식을 활용하여 응답을 생성합니다.\"\n",
    "]\n",
    "\n",
    "doc_embeddings = embeddings.embed_documents(documents)\n",
    "\n",
    "print(f\"임베딩 벡터: {query_embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72f4810",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336f526e",
   "metadata": {},
   "source": [
    "임베딩 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ec97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 쿼리와 문서들 간의 코사인 유사도 한 번에 계산\n",
    "query_text = \"Langchain에 대해 알려주세요\"\n",
    "query_emb = embeddings.embed_query(query_text) # 쿼리 임베딩\n",
    "\n",
    "doc_matrix = np.array(doc_embeddings)\n",
    "\n",
    "# reshape\n",
    "query_vector = np.array(query_emb).reshape(1, -1)\n",
    "\n",
    "\n",
    "# 벡터화된 코사인 유사도 계산\n",
    "similarities = cosine_similarity(query_vector, doc_matrix)[0]\n",
    "\n",
    "# 출력\n",
    "print(f\"쿼리: {query_text}\")\n",
    "print(\"\\n문서별 유사도:\")\n",
    "for i, (sim, doc) in enumerate(zip(similarities, documents)):\n",
    "    print(f\"문서 {i+1} (유사도: {sim:.4f}): {doc[:50]}...\")\n",
    "\n",
    "# 가장 유사한 문서 출력\n",
    "most_similar_idx = np.argmax(similarities)\n",
    "print(f\"\\n가장 유사한 문서: {documents[most_similar_idx]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
