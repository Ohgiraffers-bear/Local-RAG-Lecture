{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "700e8072",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Token Text Splitter\n",
    "`TokenTextSplitter`는 **토큰 단위**로 텍스트를 분할하는 도구입니다.  \n",
    "문자 수가 아닌 **실제 토큰 수**를 기준으로 분할하여, LLM 모델의 토큰 제한에 정확히 맞출 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4468f0",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 주요 매개변수\n",
    "- `encoding_name`: tiktoken 인코딩 이름 (cl100k_base, p50k_base 등)\n",
    "- `model_name`: LLM 모델명 (gpt-4, gpt-3.5-turbo 등)\n",
    "- `chunk_size`: 각 청크의 최대 토큰 수\n",
    "- `chunk_overlap`: 인접 청크 간 겹치는 토큰 수\n",
    "- `allowed_special`: 분할 시 유지할 특수 토큰\n",
    "- `disallowed_special`: 분할 시 제거할 특수 토큰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6c8495",
   "metadata": {},
   "source": [
    "`tiktoken`은 OpenAI에서 개발한 토큰화 라이브러리입니다.\n",
    "- GPT 모델들이 사용하는 것과 동일한 토크나이저를 제공하여 정확한 토큰 수를 계산할 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c7f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "\n",
    "# 기본 사용법 예제 1: GPT 모델용 토큰 분할\n",
    "sample_text = \"\"\"\n",
    "인공지능과 머신러닝이 급속도로 발전하고 있습니다. 자연어 처리 분야에서 Transformer 모델이 혁신을 이끌고 있으며, GPT, BERT, T5 등의 모델들이 놀라운 성능을 보여주고 있습니다.\n",
    "\n",
    "이러한 기술들은 다양한 실무 영역에 적용되고 있습니다. 번역, 요약, 질의응답, 코드 생성, 창작 등 거의 모든 언어 관련 작업에서 인간 수준의 성능을 달성하고 있습니다.\n",
    "\n",
    "특히 대화형 AI와 챗봇 개발에서 토큰 기반 텍스트 분할은 매우 중요합니다. 정확한 토큰 계산을 통해 API 비용을 최적화하고, 모델의 컨텍스트 길이 제한을 효율적으로 관리할 수 있습니다.\n",
    "\"\"\"\n",
    "\n",
    "# GPT-4 모델용 토큰 분할\n",
    "token_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=50,               # 토큰 50개 단위로 분할\n",
    "    chunk_overlap=10             # 토큰 10개씩 겹침\n",
    ")\n",
    "\n",
    "# 텍스트 분할 실행\n",
    "token_chunks = token_splitter.split_text(sample_text)\n",
    "print(f\"총 {len(token_chunks)}개 청크 생성\\n\")\n",
    "print(token_chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51400812",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 3. 다양한 토크나이저 선택\n",
    "`TokenTextSplitter`의 진정한 장점은 **다양한 토크나이저 지원**에 있습니다.  \n",
    "각 LLM 모델에 맞는 토크나이저를 선택하여 최적의 분할 결과를 얻을 수 있습니다.\n",
    "\n",
    "**HuggingFace Transformers**\n",
    "- 오픈소스 모델 및 HuggingFace에 업로드된 다양한 토크나이저를 사용할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511a8fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_text = \"\"\"제1장: 머신러닝 기초\n",
    "\n",
    "머신러닝은 인공지능의 핵심 분야로, 컴퓨터가 데이터로부터 자동으로 학습하여 패턴을 찾고 예측을 수행하는 기술입니다.\n",
    "\n",
    "주요 학습 방법들:\n",
    "지도학습 - 레이블된 데이터를 사용하여 모델을 훈련시키는 방법입니다. 분류와 회귀 문제에 사용됩니다. 예시로는 이메일 스팸 필터링, 주식 가격 예측, 고객 세분화, 의료 진단 보조 시스템 등이 있습니다.\n",
    "비지도학습 - 레이블이 없는 데이터에서 숨겨진 패턴을 찾는 방법으로 클러스터링과 차원 축소에 활용됩니다.\n",
    "\n",
    "강화학습은 에이전트가 환경과 상호작용하면서 보상을 통해 최적의 정책을 학습하는 방법입니다. 게임 AI, 로봇 제어, 자율주행 등에 활용됩니다.\n",
    "\n",
    "제2장: 딥러닝 아키텍처\n",
    "\n",
    "딥러닝은 인공 신경망을 기반으로 한 머신러닝의 하위 분야입니다. CNN은 합성곱 신경망으로 이미지 인식에 특화되어 있습니다. RNN은 순환 신경망으로 시계열 데이터와 자연어 처리에 적합합니다. Transformer는 어텐션 메커니즘을 기반으로 한 최신 아키텍처로 GPT, BERT, T5 등의 기반이 됩니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"K-intelligence/Midm-2.0-Base-Instruct\")\n",
    "\n",
    "splitter = TokenTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=tokenizer,\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=10\n",
    ")\n",
    "\n",
    "docs = splitter.split_text(comparison_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e335227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d178563a",
   "metadata": {},
   "source": [
    "한글은 자소단위로 분리될 수 있기 때문에, 한글자가 토크나이저에 의해 잘리면서 � 이러한 문자로 보일 수 있다.\n",
    "\n",
    "따라서, 문자단위로 나누어주는 `CharacterTextSplitter`를 사용하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb029ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"K-intelligence/Midm-2.0-Base-Instruct\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=tokenizer,\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=10\n",
    ")\n",
    "\n",
    "docs = splitter.split_text(comparison_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
